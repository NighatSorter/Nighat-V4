{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPGGNRK4eD8+fpBKFEujKMZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4_uI_UZil0H8"},"outputs":[],"source":["import logging\n","import warnings\n","import cv2\n","import torch\n","from torchvision.ops import nms  # Import NMS from PyTorch\n","from ultralytics import YOLO\n","from pypylon import pylon\n","import httpx  # For sending HTTP requests\n","import os  # For creating directories\n","from concurrent.futures import ThreadPoolExecutor\n","\n","# Parameters\n","fps = 30  # Desired frame rate\n","exposure_time = 500  # Exposure time in microseconds\n","width = 1900  # Width of the image\n","height = 500 # Height of the image\n","offset_x = 0  # Offset X\n","offset_y = 512  # Offset Y\n","area_threshold = 2500  # Area threshold for object detection\n","\n","# Raspberry Pi API URL\n","raspberry_pi_url = \"http://192.168.5.118:8000/control-valve/\"\n","\n","# Relaxation pixels\n","pixel_relaxation = 5\n","\n","def match_with_relaxation(detection_coords, prev_coords, relaxation=pixel_relaxation):\n","    x1, y1, x2, y2 = detection_coords\n","    px1, py1, px2, py2 = prev_coords\n","    return (px1 - relaxation <= x1 <= px1 + relaxation and\n","            py1 - relaxation <= y1 <= py1 + relaxation and\n","            px2 - relaxation <= x2 <= px2 + relaxation and\n","            py2 - relaxation <= y2 <= py2 + relaxation)\n","\n","# Suppress the specific warning about weights_only\n","warnings.filterwarnings(\"ignore\", message=\"It is possible to construct malicious pickle data\")\n","\n","# Set up logging to a file\n","logging.basicConfig(filename='./server_requests.log',\n","                    level=logging.INFO,\n","                    format='%(asctime)s %(levelname)s %(message)s')\n","\n","device = torch.device(\"cuda:0\")\n","print(device)\n","\n","# Load the YOLO model\n","model = YOLO(\"512 - augmentation - V3.pt\").to(device)\n","\n","# Configure Basler camera\n","camera = pylon.InstantCamera(pylon.TlFactory.GetInstance().CreateFirstDevice())\n","camera.Open()\n","\n","# Set the camera parameters\n","camera.AcquisitionFrameRateEnable.SetValue(True)\n","camera.AcquisitionFrameRate.SetValue(fps)\n","camera.Width.SetValue(width)\n","camera.Height.SetValue(height)\n","camera.OffsetX.SetValue(offset_x)\n","camera.OffsetY.SetValue(offset_y)\n","camera.ExposureTime.SetValue(exposure_time)  # Set exposure time in microseconds\n","\n","# Start image acquisition\n","camera.StartGrabbing(pylon.GrabStrategy_LatestImageOnly)\n","\n","# Image converter to OpenCV format\n","converter = pylon.ImageFormatConverter()\n","converter.OutputPixelFormat = pylon.PixelType_BGR8packed\n","converter.OutputBitAlignment = pylon.OutputBitAlignment_MsbAligned\n","\n","counter = 0\n","send_counter = 0\n","\n","# Create a directory for saving images if it doesn't exist\n","if not os.path.exists('img'):\n","    os.makedirs('img')\n","\n","# Function to save the detected image\n","def save_image(image, path):\n","    cv2.imwrite(path, image)\n","    logging.info(f\"Image saved at {path}\")\n","\n","# Function to send the command to the Raspberry Pi\n","def send_valve_command(valve_id):\n","    try:\n","        response = httpx.get(f\"{raspberry_pi_url}?valve_id={valve_id}\")\n","        logging.info(f\"Command sent to Raspberry Pi for valve {valve_id}: {response.status_code}\")\n","    except Exception as e:\n","        logging.error(f\"Error sending command to Raspberry Pi: {e}\")\n","\n","# Main loop for image acquisition and YOLO detection\n","with ThreadPoolExecutor() as executor:  # Thread pool for parallel tasks\n","    while camera.IsGrabbing():\n","        grabResult = camera.RetrieveResult(5000, pylon.TimeoutHandling_ThrowException)\n","\n","        if grabResult.GrabSucceeded():\n","            # Convert image to OpenCV format\n","            image = converter.Convert(grabResult)\n","            frame = image.GetArray()\n","\n","            # Resize frame for processing\n","            height, width = frame.shape[:2]\n","            scaling_factor = 512 / max(width, height)\n","            new_w = int(width * scaling_factor)\n","            new_h = int(height * scaling_factor)\n","            middle_line_y = new_h // 2\n","            frame = cv2.resize(frame, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n","\n","            # Crop the frame to get only the left half\n","            left_half = frame[:, :new_w // 2]\n","\n","            # Run YOLO for detection inference on the left half\n","            results = model.predict(left_half, show=False)\n","\n","            boxes = results[0].boxes.xyxy.cpu()  # Extract bounding boxes\n","            confidences = results[0].boxes.conf.cpu()  # Extract confidences\n","            class_ids = results[0].boxes.cls.cpu()  # Extract class IDs\n","\n","            # Convert confidences to a tensor\n","            confidences_tensor = torch.tensor(confidences)\n","\n","            # Apply NMS (Non-Maximum Suppression)\n","            nms_indices = nms(boxes, confidences_tensor, iou_threshold=0.5)\n","\n","            # Filter out the boxes, confidences, and class_ids using NMS results\n","            nms_boxes = boxes[nms_indices]\n","            nms_confidences = confidences_tensor[nms_indices]\n","            nms_class_ids = class_ids[nms_indices]\n","\n","            # Draw lines on the left half\n","            left_half = cv2.line(left_half, (0, new_h // 2), (new_w // 2, new_h // 2), (255, 255, 255), 2)\n","\n","            # Loop through NMS-filtered detections and draw them on the left half\n","            for i, (box, conf, class_id) in enumerate(zip(nms_boxes, nms_confidences, nms_class_ids)):\n","                x1, y1, x2, y2 = map(int, box)\n","                area = (x2 - x1) * (y2 - y1)\n","                area_label = f\"Area: {area}\"\n","                label = f\"Class {int(class_id)} - {area_label}\"\n","\n","                # SETTING AREA THRESHOLD\n","                if area < area_threshold:\n","                    continue\n","\n","\n","                center_x = (x1 + x2) // 2\n","                center_y = (y1 + y2) // 2\n","\n","                cv2.rectangle(left_half, (x1, y1), (x2, y2), (255, 255, 255), 1)\n","                cv2.putText(left_half, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 255, 255), 1)\n","\n","                if middle_line_y - 15 <= center_y <= middle_line_y + 15:\n","                # Save the image and send the command in parallel\n","                    image_path = f'img/{counter}.jpg'\n","                    executor.submit(save_image, left_half.copy(), image_path)\n","\n","                    valve_id = int(str(3) + str(int(class_id) + 1))  # Create valve command\n","                    executor.submit(send_valve_command, valve_id)\n","\n","                    counter += 1\n","                    print(\"=================> \", label)\n","\n","            # Display the left half\n","            cv2.imshow(\"Left Half Stream\", left_half)\n","\n","            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n","                break\n","\n","        grabResult.Release()\n","\n","# Cleanup\n","camera.StopGrabbing()\n","camera.Close()\n","cv2.destroyAllWindows()"]}]}